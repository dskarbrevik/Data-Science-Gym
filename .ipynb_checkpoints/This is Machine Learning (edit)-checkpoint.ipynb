{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Machine Learning\n",
    "\n",
    "I am starting this on 1/4/2018. My plan is to practice one machine learning algorithm or relevant technique a day for the foreseeable future. I just graduated from a master's program in data science, and am doing this to review/reinforce concepts I've learned and hopefully learn a few new things along the way. We'll see how this goes...\n",
    "\n",
    "**[update 1/5/2018]**\n",
    "Structured the notebook to have three key sections: \"Core Concepts\", \"Practice Datasets\", and \"ML Algorithms\". The core concepts section will be a high level overview of keywords and ideas that are used regularly in ML work. The \"Practice Datasets\" section will introduce the datasets that will be used for evaluation in \"ML Algorithms\" and it will be a useful place to practice performing EDA. The final \"ML Algorithms\" sections will hopefully be the meat of the notebook where each subsection will be a unique ML algorithm that is explored in some depth.\n",
    "\n",
    "**[update 1/25/2018]**\n",
    "Decided to restructure this notebook to revolve around the data. I'm going to make each section be a single dataset that gets attacked with the following workflow: background info -> EDA -> models -> visualizations/resulting remarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "\n",
    "    <li><a href=\"#section1\">LEVEL 1: What flower is this?</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#section1_1\">Introduction to the Data</a></li>\n",
    "            <li><a href=\"#section1_2\">Exploratory Data Analysis</a></li>     \n",
    "            <li><a href=\"#section1_3\">Modeling</a></li> \n",
    "            <li><a href=\"#section1_4\">Results</a></li>             \n",
    "        </ol>\n",
    "    <br>\n",
    "    <li><a href=\"#section1\">LEVEL 2: What number is this?</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#section1_1\">Introduction to the Data</a></li>\n",
    "            <li><a href=\"#section1_2\">Exploratory Data Analysis</a></li>     \n",
    "            <li><a href=\"#section1_3\">Modeling</a></li> \n",
    "            <li><a href=\"#section1_4\">Results</a></li>             \n",
    "        </ol>\n",
    "    <br>        \n",
    "    <li><a href=\"#section1\">LEVEL 3: ?</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#section1_1\">Introduction to the Data</a></li>\n",
    "            <li><a href=\"#section1_2\">Exploratory Data Analysis</a></li>     \n",
    "            <li><a href=\"#section1_3\">Modeling</a></li> \n",
    "            <li><a href=\"#section1_4\">Results</a></li>             \n",
    "        </ol>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into any code, we'll load some base libraries that we'll make regular use of. Other libraries will be imported as needed in the code below:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from inspect import getmembers\n",
    "from collections import OrderedDict, Counter\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"#toc\">back to top</a>\n",
    "</div>\n",
    "<a id='section1'></a>\n",
    "\n",
    "# Level 1: What flower is this?\n",
    "\n",
    "**Dataset:** Iris dataset\n",
    "\n",
    "**Problem type:** classification\n",
    "\n",
    "**Difficulty:** very easy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2_1'></a>\n",
    "\n",
    "## Introduction to the Dataset\n",
    "\n",
    "This is a small, 150 observations, classification type dataset where each row corresponds to one of three types of flowers. There are just four features in each row to allow for the classification of flower type (sepal length, sepal width, pedal width, pedal length). More information can be found <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris() # data imported from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA on the dataset\n",
    "\n",
    "Let's turn this into a Pandas DataFrame for a little EDA fun. It's probably a little overkill to do this on such a small dataset. We could very well do some basic analysis on it as is, but this will be a nice exercise anyway..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower Type: 150\n",
      "Sepal Length: 150\n",
      "Sepal Width: 150\n",
      "Petal Length: 150\n",
      "Petal Width: 150\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# convert numerical categories to their actual flower names\n",
    "flower_type = []\n",
    "for i in iris.target:\n",
    "        flower_type.append(iris.target_names[i])        \n",
    "\n",
    "# create an ordered dictionary with all our features\n",
    "iris_dict = OrderedDict([('Flower Type', flower_type), ('Sepal Length', iris.data[:, 0]), ('Sepal Width', iris.data[:, 1]), \n",
    "                         ('Petal Length', iris.data[:, 2]), ('Petal Width', iris.data[:, 3])])\n",
    "\n",
    "# quickly verify that all arrays are the same length\n",
    "for key in iris_dict.keys():\n",
    "    print(\"{0}: {1}\".format(key, len(iris_dict[key])))\n",
    "\n",
    "# make Pandas DataFrame from ordered dictionary\n",
    "iris_df = pd.DataFrame.from_dict(iris_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 150 observations (rows) and 5 features (columns).\n"
     ]
    }
   ],
   "source": [
    "print(\"This dataset has {} observations (rows) and {} features (columns).\".format(iris_df.shape[0], iris_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flower Type</th>\n",
       "      <th>Sepal Length</th>\n",
       "      <th>Sepal Width</th>\n",
       "      <th>Petal Length</th>\n",
       "      <th>Petal Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Flower Type  Sepal Length  Sepal Width  Petal Length  Petal Width\n",
       "0      setosa           5.1          3.5           1.4          0.2\n",
       "1      setosa           4.9          3.0           1.4          0.2\n",
       "2      setosa           4.7          3.2           1.3          0.2\n",
       "3      setosa           4.6          3.1           1.5          0.2\n",
       "4      setosa           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal Length</th>\n",
       "      <th>Sepal Width</th>\n",
       "      <th>Petal Length</th>\n",
       "      <th>Petal Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sepal Length  Sepal Width  Petal Length  Petal Width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see there are just a few features and not many observations in this dataset. Note the first few lines are all \"setosa\", this is because the dataset is ordered. The first 50 rows are Setosa, the next 50 are versicolor, and the last 50 rows are virginica. Also, we can note from the basic statistics of the features that the pedal length seems to have a particularly high standard deviation and thus may be the most valuable feature in differentiating the different flowers (just a hunch, not a for sure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29782a53fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "n_neighbors = 1\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# we only take the first two features. We could avoid this ugly\n",
    "# slicing by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf = KNeighborsClassifier(n_neighbors)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "            edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"k-NN Classification of Iris Dataset (k = %i)\"\n",
    "          % (n_neighbors))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"#toc\">back to top</a>\n",
    "</div>\n",
    "<a id='section3'></a>\n",
    "\n",
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3_1'></a>\n",
    "\n",
    "## k-Nearest Neighbor (k-NN)\n",
    "\n",
    "k-NN is the idea that you can predict the correct label for a data point based on the labels of it's closest neighbors. If you wanted to know how much it would cost to ship a package from location X to Florida and you only knew the cost of shipping from X to California and X to Georgia... probably assume that since Georgia is so close to Florida it would cost something simliar to that shipping price and ignore the cost of shipping to California. This is k-NN, where k is the number of neighbors to consider when making a decision. Consider our shipping situation again, but this time imagine we have way more data. We know the price to ship from location X to any city in the U.S. except Tampa Bay, Florida. If we use k-NN with k = 1, we would look for the city closest to Tampa Bay and decide that whatever the shipping rate is there, it will be the same for Tampa Bay. However, if we want k to equal 3, we would look at the three closest cities to Tampa Bay and choose the shipping cost most common to them. For instance if two of the three cities cost \\$5 to ship and for a third city the cost is \\$3, we will choose the majority cost of \\$5 as the shipping fee to Tampa Bay. \n",
    "\n",
    "KNN is a **non-parametric** and **lazy** algorithm. These ideas are somewhat related in that you may expect a \"lazy\" algorithm would be non-parametric. \n",
    "\n",
    "The algorithm is non-parametric because the hyperparameter K, changes the number of parameters the model will use. The number of parameters must be fixed in the model for it to be parametric. \n",
    "\n",
    "KNN algorithm is \"lazy\" because there is no actual training phase. Most other algorithms take a set of training data, learn some sort of formula for how best to classify, regress, etc. (optimize whatever objective function) the data. Then you come along with a new data point for the trained algorithm to make a prediction on. When it makes the prediction, it doesn't require the training data any longer, it has already _learned_ what it will from the training data. However, with KNN there is no actual training phase, the \"training\" happens at **inference**; KNN maps the new data point of interest to where it should best fit amongst the training data you gave it. Effectively instead of doing any \"training\" or \"learning\" it just memorized the training data and maps new values inside the training data. Ultimately the takeaway is that the algorithm doesn't have to do anything until you want a prediction, so we call it lazy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting our data ready\n",
    "\n",
    "We'll use the Iris dataset to evaluate our models. Because KNN is a sort of mapping algorithm, it works well for data that has good spatial separation and a low number of feautres/dimensions.\n",
    "\n",
    "Note that because this algorithm is lazy, we don't actually need to split train/test data. We can use the full dataset minus the datapoint of interest as the \"training data\", however in the spirit of machine learning workflow we will create a train/test anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = iris.data[:,:2]\n",
    "labels = flower_type\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=.20, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homegrown solution\n",
    "\n",
    "This algorithm expects coordinate like input features (two numbers) and an associated label (any text/number/whatever). So something like [(-3.4, 5), \"blue\"].\n",
    "\n",
    "You can technically use any number of features with KNN, but the \"curse of dimensionality\" sets in quickly. More on this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HG_KNN_Classifier():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def euclidean_distance(self, x, y):\n",
    "        if len(x) != len(y):\n",
    "            raise Exception(\"Values in dataset don't have the same dimensions.\")\n",
    "        distance = 0.0\n",
    "        for i in range(len(x)):\n",
    "            distance += (x[i] - y[i])**2\n",
    "        distance = np.sqrt(distance)\n",
    "        return distance\n",
    "\n",
    "    def manhattan_distance(self, x, y):\n",
    "        if len(x) != len(y):\n",
    "            raise Exception(\"Values in dataset don't have the same dimensions.\")\n",
    "        distance = 0\n",
    "        for i in range(len(x)):\n",
    "            distance += np.abs(x[i] - y[i])\n",
    "        return distance    \n",
    "\n",
    "    def predict(self, k, labeled_train_points, test_points, distance=\"euclidean\"):\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # if there's only one data point to make a prediction on\n",
    "        if (isinstance(test_points[0], numbers.Number)):\n",
    "            test_points = [test_points] \n",
    "            \n",
    "        for i in range(len(test_points)):\n",
    "            if distance == \"euclidean\":\n",
    "                by_distance = sorted(labeled_train_points, key=lambda data: self.euclidean_distance(data[0], test_points[i]))\n",
    "            elif distance == \"manhattan\":\n",
    "                by_distance = sorted(labeled_train_points, key=lambda data: self.manhattan_distance(data[0], test_points[i]))\n",
    "                \n",
    "            k_nearest_labels = [label for _, label in by_distance[:k]] \n",
    "            \n",
    "            while(True):\n",
    "                vote_counts = Counter(k_nearest_labels)\n",
    "                winner, winner_count = vote_counts.most_common(1)[0]\n",
    "\n",
    "                num_winners = len([count for count in vote_counts.values() if count == winner_count])\n",
    "                if num_winners == 1:\n",
    "                    predictions.append(winner)\n",
    "                    break\n",
    "                else:\n",
    "                    k_nearest_labels = k_nearest_labels[:-1]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_train_data = list(zip(train_data, train_labels))\n",
    "k_val = 2\n",
    "knn_model = HG_KNN_Classifier()\n",
    "hg_predictions = knn_model.predict(k=k_val, labeled_train_points=labeled_train_data, test_points=test_data, distance=\"manhattan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of homegrown k-NN model with k = 2: 66.67%\n"
     ]
    }
   ],
   "source": [
    "acc_score = 0\n",
    "for i in range(len(hg_predictions)):\n",
    "    if hg_predictions[i] == test_labels[i]:\n",
    "        acc_score += 1\n",
    "acc_score /= len(hg_predictions)\n",
    "\n",
    "print(\"Accuracy of homegrown k-NN model with k = {}: {:.2f}%\".format( k_val, (acc_score*100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. Very simple implemenation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn solution\n",
    "\n",
    "Using a standard scikit-learn implementation to show how easy it is and to benchmark against our homegrown solution. Note how simple sklearn is to implement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of k-NN with k = 2 : 76.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_neighbors = 2\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors)\n",
    "knn.fit(train_data, train_labels)\n",
    "preds = knn.predict(test_data)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, preds)\n",
    "print(\"Accuracy of k-NN with k = {} : {:.2f}%\".format(n_neighbors, (accuracy*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you're looking at:\n",
    "\n",
    "The three regions of background color represent the decision boundaries of our k-NN model while the dots represent the actual data we provided to make those boundaries. \n",
    "\n",
    "Notice how some of the dots are not in the right k-NN decision boundary? Why do you think that is (hint: consider how the decision boundary would be different for k=1 vs. k=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3_2'></a>\n",
    "\n",
    "## \n",
    "\n",
    "This algorithm is blah blah blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homegrown solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-learn solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Points of focus:\n",
    "\n",
    "Use cases:\n",
    "\n",
    "Pros:\n",
    "\n",
    "Cons:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** classification : **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** features/observations : ** Typically refers to the rows/columns (respectively) of a table/dataset. For example, imagine I have 50 patients and I give them Drug A (some drug I think will lowers body fat) and then I measure their weight before taking the drug and then again after a month. The resulting dataset will have 50 observations (one for each patient) with 2 features (a before weight and an after weight). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** generative model : **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** inference time : **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** non-parametric model : ** Not to be confused with a \"non-parametric statistic\", when used in the context of a model, non-parametric refers to a model that does not have a fixed number of parameters. In the case of KNN, the value of K determines how many parameters the model will have but this can be changed at inference time, not fixed based on the model so we call this non-parametric. Note that this does not mean there are _not_ parameters, just that they are not fixed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** observation/features : ** Typically refers to the rows/columns (respectively) of a table/dataset. For example, imagine I have 50 patients and I give them Drug A (some drug I think will lowers body fat) and then I measure their weight before taking the drug and then again after a month. The resulting dataset will have 50 observations (one for each patient) with 2 features (a before weight and an after weight). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** training time : **"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
